{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import prepare\n",
    "# nltk.download('wordnet') - needed to run to download 'wordnet' resource to use lemmatize function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gocodeup/codeup-setup-script</td>\n",
       "      <td>Shell</td>\n",
       "      <td># Codeup Setup Script\\n\\nSetup script for Code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gocodeup/movies-application</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Movies Application\\n\\nFor this project, we w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>torvalds/linux</td>\n",
       "      <td>C</td>\n",
       "      <td>Linux kernel\\n============\\n\\nThere are severa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beetbox/beets</td>\n",
       "      <td>Python</td>\n",
       "      <td>.. image:: https://img.shields.io/pypi/v/beets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scottschiller/SoundManager2</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># SoundManager 2: JavaScript Sound for the Web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>fastai/courses</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Practical Deep Learning for Coders (fast.ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Yorko/mlcourse.ai</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n\\n![ODS stickers](https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>jtoy/awesome-tensorflow</td>\n",
       "      <td>None</td>\n",
       "      <td># Awesome TensorFlow  [![Awesome](https://cdn....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>nlintz/TensorFlow-Tutorials</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># TensorFlow-Tutorials\\n[![Build Status](https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>pkmital/tensorflow_tutorials</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># UPDATE (July 12, 2016)\\n\\nNew **free MOOC co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             repo          language  \\\n",
       "0    gocodeup/codeup-setup-script             Shell   \n",
       "1     gocodeup/movies-application        JavaScript   \n",
       "2                  torvalds/linux                 C   \n",
       "3                   beetbox/beets            Python   \n",
       "4     scottschiller/SoundManager2        JavaScript   \n",
       "..                            ...               ...   \n",
       "107                fastai/courses  Jupyter Notebook   \n",
       "108             Yorko/mlcourse.ai            Python   \n",
       "109       jtoy/awesome-tensorflow              None   \n",
       "110   nlintz/TensorFlow-Tutorials  Jupyter Notebook   \n",
       "111  pkmital/tensorflow_tutorials  Jupyter Notebook   \n",
       "\n",
       "                                       readme_contents  \n",
       "0    # Codeup Setup Script\\n\\nSetup script for Code...  \n",
       "1    # Movies Application\\n\\nFor this project, we w...  \n",
       "2    Linux kernel\\n============\\n\\nThere are severa...  \n",
       "3    .. image:: https://img.shields.io/pypi/v/beets...  \n",
       "4    # SoundManager 2: JavaScript Sound for the Web...  \n",
       "..                                                 ...  \n",
       "107  # Practical Deep Learning for Coders (fast.ai ...  \n",
       "108  <div align=\"center\">\\n\\n![ODS stickers](https:...  \n",
       "109  # Awesome TensorFlow  [![Awesome](https://cdn....  \n",
       "110  # TensorFlow-Tutorials\\n[![Build Status](https...  \n",
       "111  # UPDATE (July 12, 2016)\\n\\nNew **free MOOC co...  \n",
       "\n",
       "[112 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep_data(df, 'readme_contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gocodeup/movies-application</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Movies Application\\n\\nFor this project, we w...</td>\n",
       "      <td>movi applic for thi project we will be build a...</td>\n",
       "      <td>movie application for this project we will be ...</td>\n",
       "      <td>movie application building single page movie a...</td>\n",
       "      <td>367</td>\n",
       "      <td>417</td>\n",
       "      <td>[movie, application, building, single, page, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torvalds/linux</td>\n",
       "      <td>C</td>\n",
       "      <td>Linux kernel\\n============\\n\\nThere are severa...</td>\n",
       "      <td>linux kernel there are sever guid for kernel d...</td>\n",
       "      <td>linux kernel there are several guide for kerne...</td>\n",
       "      <td>linux kernel several guide kernel developer us...</td>\n",
       "      <td>39</td>\n",
       "      <td>71</td>\n",
       "      <td>[linux, kernel, several, guide, kernel, develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beetbox/beets</td>\n",
       "      <td>Python</td>\n",
       "      <td>.. image:: https://img.shields.io/pypi/v/beets...</td>\n",
       "      <td>imag http img shield io pypi v beet svg target...</td>\n",
       "      <td>image http img shield io pypi v beet svg targe...</td>\n",
       "      <td>image http img shield io pypi v beet svg targe...</td>\n",
       "      <td>205</td>\n",
       "      <td>518</td>\n",
       "      <td>[image, http, img, shield, io, pypibeet, svg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scottschiller/SoundManager2</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># SoundManager 2: JavaScript Sound for the Web...</td>\n",
       "      <td>soundmanag javascript sound for the web by wra...</td>\n",
       "      <td>soundmanager javascript sound for the web by w...</td>\n",
       "      <td>soundmanager javascript sound web wrapping ext...</td>\n",
       "      <td>316</td>\n",
       "      <td>603</td>\n",
       "      <td>[soundmanager, javascript, sound, web, wrappin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CreateJS/SoundJS</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># SoundJS\\r\\n\\r\\nSoundJS is a library to make ...</td>\n",
       "      <td>soundj soundj is a librari to make work with a...</td>\n",
       "      <td>soundjs soundjs is a library to make working w...</td>\n",
       "      <td>soundjs soundjs make working audio web easier ...</td>\n",
       "      <td>160</td>\n",
       "      <td>350</td>\n",
       "      <td>[soundjs, soundjs, make, working, audio, web, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>Python</td>\n",
       "      <td># Awesome Machine Learning [![Awesome](https:/...</td>\n",
       "      <td>awesom machin learn awesom http cdn rawgit com...</td>\n",
       "      <td>awesome machine learning awesome http cdn rawg...</td>\n",
       "      <td>awesome machine learning awesome http cdn rawg...</td>\n",
       "      <td>5027</td>\n",
       "      <td>16878</td>\n",
       "      <td>[awesome, machine, learning, awesome, http, cd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>fastai/courses</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Practical Deep Learning for Coders (fast.ai ...</td>\n",
       "      <td>practic deep learn for coder fast ai cours the...</td>\n",
       "      <td>practical deep learning for coder fast ai cour...</td>\n",
       "      <td>practical deep learning coder fast ai course l...</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>[practical, deep, learning, coder, fast, ai, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Yorko/mlcourse.ai</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n\\n![ODS stickers](https:...</td>\n",
       "      <td>div align center od sticker http github com yo...</td>\n",
       "      <td>div align center od sticker http github com yo...</td>\n",
       "      <td>div align center od sticker http com yorko mlc...</td>\n",
       "      <td>218</td>\n",
       "      <td>2037</td>\n",
       "      <td>[div, align, center, od, sticker, http, com, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>nlintz/TensorFlow-Tutorials</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># TensorFlow-Tutorials\\n[![Build Status](https...</td>\n",
       "      <td>tensorflow tutori build statu http travi ci or...</td>\n",
       "      <td>tensorflow tutorial build status http travis c...</td>\n",
       "      <td>tensorflow tutorial build status http travis c...</td>\n",
       "      <td>12</td>\n",
       "      <td>140</td>\n",
       "      <td>[tensorflow, tutorial, build, status, http, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pkmital/tensorflow_tutorials</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># UPDATE (July 12, 2016)\\n\\nNew **free MOOC co...</td>\n",
       "      <td>updat juli 12 2016 new free mooc cours cover a...</td>\n",
       "      <td>update july 12 2016 new free mooc course cover...</td>\n",
       "      <td>update july 12 2016 new free mooc course cover...</td>\n",
       "      <td>72</td>\n",
       "      <td>327</td>\n",
       "      <td>[update, july, 12, 2016, new, free, mooc, cour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     repo          language  \\\n",
       "0             gocodeup/movies-application        JavaScript   \n",
       "1                          torvalds/linux                 C   \n",
       "2                           beetbox/beets            Python   \n",
       "3             scottschiller/SoundManager2        JavaScript   \n",
       "4                        CreateJS/SoundJS        JavaScript   \n",
       "..                                    ...               ...   \n",
       "91  josephmisiti/awesome-machine-learning            Python   \n",
       "92                         fastai/courses  Jupyter Notebook   \n",
       "93                      Yorko/mlcourse.ai            Python   \n",
       "94            nlintz/TensorFlow-Tutorials  Jupyter Notebook   \n",
       "95           pkmital/tensorflow_tutorials  Jupyter Notebook   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "0   # Movies Application\\n\\nFor this project, we w...   \n",
       "1   Linux kernel\\n============\\n\\nThere are severa...   \n",
       "2   .. image:: https://img.shields.io/pypi/v/beets...   \n",
       "3   # SoundManager 2: JavaScript Sound for the Web...   \n",
       "4   # SoundJS\\r\\n\\r\\nSoundJS is a library to make ...   \n",
       "..                                                ...   \n",
       "91  # Awesome Machine Learning [![Awesome](https:/...   \n",
       "92  # Practical Deep Learning for Coders (fast.ai ...   \n",
       "93  <div align=\"center\">\\n\\n![ODS stickers](https:...   \n",
       "94  # TensorFlow-Tutorials\\n[![Build Status](https...   \n",
       "95  # UPDATE (July 12, 2016)\\n\\nNew **free MOOC co...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   movi applic for thi project we will be build a...   \n",
       "1   linux kernel there are sever guid for kernel d...   \n",
       "2   imag http img shield io pypi v beet svg target...   \n",
       "3   soundmanag javascript sound for the web by wra...   \n",
       "4   soundj soundj is a librari to make work with a...   \n",
       "..                                                ...   \n",
       "91  awesom machin learn awesom http cdn rawgit com...   \n",
       "92  practic deep learn for coder fast ai cours the...   \n",
       "93  div align center od sticker http github com yo...   \n",
       "94  tensorflow tutori build statu http travi ci or...   \n",
       "95  updat juli 12 2016 new free mooc cours cover a...   \n",
       "\n",
       "                                           lemmatized  \\\n",
       "0   movie application for this project we will be ...   \n",
       "1   linux kernel there are several guide for kerne...   \n",
       "2   image http img shield io pypi v beet svg targe...   \n",
       "3   soundmanager javascript sound for the web by w...   \n",
       "4   soundjs soundjs is a library to make working w...   \n",
       "..                                                ...   \n",
       "91  awesome machine learning awesome http cdn rawg...   \n",
       "92  practical deep learning for coder fast ai cour...   \n",
       "93  div align center od sticker http github com yo...   \n",
       "94  tensorflow tutorial build status http travis c...   \n",
       "95  update july 12 2016 new free mooc course cover...   \n",
       "\n",
       "                                                clean  stopwords_removed  \\\n",
       "0   movie application building single page movie a...                367   \n",
       "1   linux kernel several guide kernel developer us...                 39   \n",
       "2   image http img shield io pypi v beet svg targe...                205   \n",
       "3   soundmanager javascript sound web wrapping ext...                316   \n",
       "4   soundjs soundjs make working audio web easier ...                160   \n",
       "..                                                ...                ...   \n",
       "91  awesome machine learning awesome http cdn rawg...               5027   \n",
       "92  practical deep learning coder fast ai course l...                 60   \n",
       "93  div align center od sticker http com yorko mlc...                218   \n",
       "94  tensorflow tutorial build status http travis c...                 12   \n",
       "95  update july 12 2016 new free mooc course cover...                 72   \n",
       "\n",
       "    doc_length                                              words  \n",
       "0          417  [movie, application, building, single, page, m...  \n",
       "1           71  [linux, kernel, several, guide, kernel, develo...  \n",
       "2          518  [image, http, img, shield, io, pypibeet, svg, ...  \n",
       "3          603  [soundmanager, javascript, sound, web, wrappin...  \n",
       "4          350  [soundjs, soundjs, make, working, audio, web, ...  \n",
       "..         ...                                                ...  \n",
       "91       16878  [awesome, machine, learning, awesome, http, cd...  \n",
       "92          81  [practical, deep, learning, coder, fast, ai, c...  \n",
       "93        2037  [div, align, center, od, sticker, http, com, y...  \n",
       "94         140  [tensorflow, tutorial, build, status, http, tr...  \n",
       "95         327  [update, july, 12, 2016, new, free, mooc, cour...  \n",
       "\n",
       "[96 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          28\n",
       "Python              17\n",
       "Ruby                12\n",
       "HTML                10\n",
       "C++                  8\n",
       "Jupyter Notebook     6\n",
       "CSS                  4\n",
       "TypeScript           3\n",
       "Java                 2\n",
       "C#                   2\n",
       "Scala                2\n",
       "C                    2\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   repo               96 non-null     object\n",
      " 1   language           96 non-null     object\n",
      " 2   readme_contents    96 non-null     object\n",
      " 3   stemmed            96 non-null     object\n",
      " 4   lemmatized         96 non-null     object\n",
      " 5   clean              96 non-null     object\n",
      " 6   stopwords_removed  96 non-null     int64 \n",
      " 7   doc_length         96 non-null     int64 \n",
      " 8   words              96 non-null     object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validate = train_test_split(df, stratify=df.language, test_size=.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          22\n",
       "Python              13\n",
       "Ruby                 9\n",
       "HTML                 8\n",
       "C++                  6\n",
       "Jupyter Notebook     5\n",
       "CSS                  3\n",
       "Java                 2\n",
       "C#                   2\n",
       "C                    2\n",
       "Scala                2\n",
       "TypeScript           2\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          6\n",
       "Python              4\n",
       "Ruby                3\n",
       "HTML                2\n",
       "C++                 2\n",
       "Jupyter Notebook    1\n",
       "CSS                 1\n",
       "TypeScript          1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series objects for each top_code_clean that is a string of words joined on spaces to make it 1 continious string  \n",
    "javascript_words = ' '.join(train[train.language=='JavaScript'].clean)\n",
    "python_words = ' '.join(train[train.language=='Python'].clean)\n",
    "ruby_words = ' '.join(train[train.language=='Ruby'].clean)\n",
    "html_words = ' '.join(train[train.language=='HTML'].clean)\n",
    "c_plus_plus_words = ' '.join(train[train.language=='C++'].clean)\n",
    "all_words = ' '.join(train.clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "\n",
    "Explore the data that you have scraped. Here are some ideas for exploration:\n",
    "\n",
    "- What are the most common words in READMEs?\n",
    "- What does the distribution of IDFs look like for the most common words?\n",
    "- Does the length of the README vary by programming language?\n",
    "- Do different programming languages use a different number of unique words?\n",
    "\n",
    "### What are the most common words in READMEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df = pd.DataFrame(all_words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http          1749\n",
       "com           1049\n",
       "org            487\n",
       "00s            331\n",
       "www            245\n",
       "build          231\n",
       "tensorflow     220\n",
       "data           207\n",
       "file           186\n",
       "license        178\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_df.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the distribution of IDFs look like for the most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http',\n",
       " 'com',\n",
       " 'org',\n",
       " '00s',\n",
       " 'www',\n",
       " 'build',\n",
       " 'tensorflow',\n",
       " 'data',\n",
       " 'file',\n",
       " 'license']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the top ten most common words across the combined readmes of the train dataset\n",
    "most_common_words = [word[0] for word in list(all_words_df.value_counts().head(10).index)]\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(most_common_words):\n",
    "    # This dictionary will store how many documents each word appears in \n",
    "    appearances_dict = dict.fromkeys(most_common_words)\n",
    "    \n",
    "    # The total number of documents is based on the number of rows in the train dataframe\n",
    "    number_of_documents = train.shape[0]\n",
    "    \n",
    "    # This is essentially a list containing the contents of the words column in the dataframe. It is a list of lists.\n",
    "    list_of_wordlists = list(train.words.values)\n",
    "    \n",
    "    # Start iterating through the list of common words. We want to collect information for each one.\n",
    "    for word in most_common_words:\n",
    "        \n",
    "        # Set the initial number of documents that the word appears in to zero\n",
    "        number_of_appearances = 0\n",
    "        \n",
    "        # Start iterating through the list made from the words column in the dataframe \n",
    "        for words in list_of_wordlists:\n",
    "            \n",
    "            # If the current word is in a document, add 1 to the number of appearances and then move to the next document\n",
    "            if word in words:\n",
    "                number_of_appearances += 1\n",
    "        \n",
    "        # Once all the documents have been iterated through, add the sum total of all appearances to our appearances dictionary\n",
    "        appearances_dict[word] = number_of_appearances\n",
    "        \n",
    "    # Create a new dictionary that will contain the IDF values for each word\n",
    "    idf_dict = dict.fromkeys(most_common_words)\n",
    "    \n",
    "    # Start iterating through the list of common words again, using the number of appearances and the total number of documents to calculate the IDF and update the relevant key:value in the dictionary\n",
    "    for word in most_common_words:\n",
    "        idf_dict[word] = np.log(number_of_documents / appearances_dict[word])\n",
    "        \n",
    "    # Return the dictionary showing the actual number of appearances and the dictionary showing the calculated IDFs\n",
    "    return appearances_dict, idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'http': 75,\n",
       "  'com': 69,\n",
       "  'org': 61,\n",
       "  '00s': 1,\n",
       "  'www': 53,\n",
       "  'build': 40,\n",
       "  'tensorflow': 5,\n",
       "  'data': 26,\n",
       "  'file': 42,\n",
       "  'license': 45},\n",
       " {'http': 0.013245226750020723,\n",
       "  'com': 0.0966268356890717,\n",
       "  'org': 0.21985947611301987,\n",
       "  '00s': 4.330733340286331,\n",
       "  'www': 0.3604414267342092,\n",
       "  'build': 0.6418538861723947,\n",
       "  'tensorflow': 2.7212954278522306,\n",
       "  'data': 1.072636802264849,\n",
       "  'file': 0.5930637220029628,\n",
       "  'license': 0.5240708505160113})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the length of the README vary by programming language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Python              1086.615385\n",
       "C++                  845.333333\n",
       "Ruby                 688.666667\n",
       "JavaScript           499.363636\n",
       "HTML                 450.375000\n",
       "C#                   430.500000\n",
       "Scala                418.000000\n",
       "TypeScript           300.500000\n",
       "C                    240.000000\n",
       "CSS                  196.333333\n",
       "Jupyter Notebook     162.800000\n",
       "Java                 146.000000\n",
       "Name: doc_length, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('language').doc_length.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Document Length T-Test: Python & JavaScript\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Python and JavaScript\n",
      "H_a: There is a difference in the mean document lengths of Python and JavaScript\n",
      "\n",
      "\n",
      "p-value: 0.02265755105674392\n",
      "t-statistic: 2.0805481106603447\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Python is larger than JavaScript\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: C++ & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of C++ and Jupyter Notebook\n",
      "H_a: There is a difference in the mean document lengths of C++ and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.01831934302482318\n",
      "t-statistic: 2.4519606495569213\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for C++ is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Ruby & TypeScript\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Ruby and TypeScript\n",
      "H_a: There is a difference in the mean document lengths of Ruby and TypeScript\n",
      "\n",
      "\n",
      "p-value: 0.02263624845402492\n",
      "t-statistic: 2.3228711886909563\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Ruby is larger than TypeScript\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Ruby & C\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Ruby and C\n",
      "H_a: There is a difference in the mean document lengths of Ruby and C\n",
      "\n",
      "\n",
      "p-value: 0.016465147403430313\n",
      "t-statistic: 2.5170009989095625\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Ruby is larger than C\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Ruby & CSS\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Ruby and CSS\n",
      "H_a: There is a difference in the mean document lengths of Ruby and CSS\n",
      "\n",
      "\n",
      "p-value: 0.0025933594615662604\n",
      "t-statistic: 3.5593661422403318\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Ruby is larger than CSS\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Ruby & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Ruby and Jupyter Notebook\n",
      "H_a: There is a difference in the mean document lengths of Ruby and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.0002665356701470812\n",
      "t-statistic: 4.6791214124114715\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Ruby is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Ruby & Java\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Ruby and Java\n",
      "H_a: There is a difference in the mean document lengths of Ruby and Java\n",
      "\n",
      "\n",
      "p-value: 0.006092290662807421\n",
      "t-statistic: 3.1267887576676237\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Ruby is larger than Java\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Scala & CSS\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Scala and CSS\n",
      "H_a: There is a difference in the mean document lengths of Scala and CSS\n",
      "\n",
      "\n",
      "p-value: 0.04677021697511666\n",
      "t-statistic: 2.427481572558582\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Scala is larger than CSS\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Document Length T-Test: Scala & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean document lengths of Scala and Jupyter Notebook\n",
      "H_a: There is a difference in the mean document lengths of Scala and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.034189685340168904\n",
      "t-statistic: 2.3161679023249344\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean readme document length for Scala is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell block looks at every pair of languages and compares the document lengths using a t-test\n",
    "\n",
    "# Start by developing two identical lists of all of the languages represented in the train dataset\n",
    "# We will use the series above to form our list so our output is arranged in a similar order\n",
    "# When this is converted to a function, we can generate the list in a more generalized manner\n",
    "train_language_list_1 = list(train.groupby('language').doc_length.mean().sort_values(ascending=False).index)\n",
    "train_language_list_2 = list(train.groupby('language').doc_length.mean().sort_values(ascending=False).index)\n",
    "\n",
    "# This empty list will hold information about which pairs have been tested. \n",
    "# If the python and javascript pair has already be tested, then we do not need to test the javascript and python pair\n",
    "testing_pairs = []\n",
    "\n",
    "for language_1 in train_language_list_1: # Iterates through list 1\n",
    "    for language_2 in train_language_list_2: # Iterates through list 2 in entirety for each element in list 1\n",
    "        \n",
    "        if language_1 == language_2: # Cannot run a t-test against itself, so skip the test if the two list elements are identical\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            alpha = 0.05 # Set alpha\n",
    "            \n",
    "            # Run the t-test and store the t-statistic and the p-value\n",
    "            stat, p = stats.ttest_ind(train[train.language == language_1].doc_length, train[train.language == language_2].doc_length)\n",
    "            \n",
    "            # If the p-value is statistically significant we print the results, otherwise we do nothing\n",
    "            if p/2 < alpha:\n",
    "                \n",
    "                # Creating strings to represent the pair that is being tested (eg. 'Python and JavaScript' & 'JavaScript and Python')\n",
    "                testing_pair_1 = language_1 + \" \" + language_2\n",
    "                testing_pair_2 = language_2 + \" \" + language_1\n",
    "                \n",
    "                # If this unique pair has not yet been tested:\n",
    "                if (testing_pair_1 not in testing_pairs) and (testing_pair_2 not in testing_pairs):\n",
    "                    \n",
    "                    # Add this pair to the testing_pairs list so that we do not output duplicate t-test results\n",
    "                    testing_pairs.append(testing_pair_1)\n",
    "                    testing_pairs.append(testing_pair_2)\n",
    "                    \n",
    "                    # Print the results of the test\n",
    "                    print(\"----------------\")\n",
    "                    print(f\"Document Length T-Test: {language_1} & {language_2}\")\n",
    "                    print(\"----------------\")\n",
    "                    print(\"Hypotheses:\")\n",
    "                    print(f\"H_0: There is no difference in the mean document lengths of {language_1} and {language_2}\")\n",
    "                    print(f\"H_a: There is a difference in the mean document lengths of {language_1} and {language_2}\")\n",
    "                    print('\\n')\n",
    "                    print(f\"p-value: {p/2}\")\n",
    "                    print(f\"t-statistic: {stat}\")\n",
    "                    print(f\"We reject the null hypothesis\")\n",
    "                    print(\"\\n\")\n",
    "                    if stat < 0:\n",
    "                        print(f\"The mean readme document length for {language_1} is smaller than {language_2}\")\n",
    "                    elif stat > 0:\n",
    "                        print(f\"The mean readme document length for {language_1} is larger than {language_2}\")\n",
    "                    print('\\n','\\n')\n",
    "                    \n",
    "                    # If the pair had already been tested, do not print any results and continue through the loop\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do different programming languages use a different number of unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_count = {}\n",
    "\n",
    "for language in train_language_list_1:\n",
    "    unique_word_count[language] = len(set(' '.join(train[train.language==language].clean).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_count = pd.DataFrame.from_dict(unique_word_count, orient='index').rename(columns={0: 'num_unique_words'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruby</th>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter Notebook</th>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C#</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scala</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSS</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TypeScript</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  num_unique_words\n",
       "Python                        3400\n",
       "JavaScript                    2666\n",
       "Ruby                          1870\n",
       "C++                           1199\n",
       "HTML                          1150\n",
       "Jupyter Notebook               374\n",
       "C#                             349\n",
       "Scala                          336\n",
       "CSS                            321\n",
       "TypeScript                     231\n",
       "C                              231\n",
       "Java                           163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_count.sort_values(by='num_unique_words', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this gives us a total count of the number of unique words each programming language has connected to it, this is likely to be correlated both to the total document length AND the number of observations that each language has. Languages with more observations likely have more opportunities to expand the unique word list. \n",
    "\n",
    "A better metric would be the average number of unique words that each language has. To do this we will need to add a column to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['unique_word_count'] = train.words.apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>words</th>\n",
       "      <th>unique_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Hextris/hextris</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Hextris\\n==========\\n\\n&lt;img src=\"images/twitte...</td>\n",
       "      <td>hextri img src imag twitter opengraph png widt...</td>\n",
       "      <td>hextris img src image twitter opengraph png wi...</td>\n",
       "      <td>hextris img src image twitter opengraph png wi...</td>\n",
       "      <td>91</td>\n",
       "      <td>170</td>\n",
       "      <td>[hextris, img, src, image, twitter, opengraph,...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ahmia/ahmia-site</td>\n",
       "      <td>Python</td>\n",
       "      <td>[![Build Status](https://travis-ci.org/ahmia/a...</td>\n",
       "      <td>build statu http travi ci org ahmia ahmia site...</td>\n",
       "      <td>build status http travis ci org ahmia ahmia si...</td>\n",
       "      <td>build status http travis ci org ahmia ahmia si...</td>\n",
       "      <td>206</td>\n",
       "      <td>690</td>\n",
       "      <td>[build, status, http, travis, ci, org, ahmia, ...</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>OptiKey/OptiKey</td>\n",
       "      <td>C#</td>\n",
       "      <td># OptiKey\\n\\nOptiKey is an on-screen keyboard ...</td>\n",
       "      <td>optikey optikey is an on screen keyboard that ...</td>\n",
       "      <td>optikey optikey is an on screen keyboard that ...</td>\n",
       "      <td>optikey optikey screen keyboard designed help ...</td>\n",
       "      <td>117</td>\n",
       "      <td>235</td>\n",
       "      <td>[optikey, optikey, screen, keyboard, designed,...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nprapps/app-template</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>nprviz's Project Template\\n===================...</td>\n",
       "      <td>nprviz' project templat about thi templat abou...</td>\n",
       "      <td>nprviz's project template about this template ...</td>\n",
       "      <td>nprviz template template template assumption a...</td>\n",
       "      <td>222</td>\n",
       "      <td>304</td>\n",
       "      <td>[nprviz, template, template, template, assumpt...</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>atlemo/SubtlePatterns</td>\n",
       "      <td>HTML</td>\n",
       "      <td>Subtle Patterns\\n===============\\n\\nView all t...</td>\n",
       "      <td>subtl pattern view all the pattern from subtl ...</td>\n",
       "      <td>subtle pattern view all the pattern from subtl...</td>\n",
       "      <td>subtle pattern view pattern subtle pattern htt...</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>[subtle, pattern, view, pattern, subtle, patte...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>EFForg/action-center-platform</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>[![Build Status](https://travis-ci.org/EFForg/...</td>\n",
       "      <td>build statu http travi ci org efforg action ce...</td>\n",
       "      <td>build status http travis ci org efforg action ...</td>\n",
       "      <td>build status http travis ci org efforg action ...</td>\n",
       "      <td>449</td>\n",
       "      <td>986</td>\n",
       "      <td>[build, status, http, travis, ci, org, efforg,...</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MonoGame/MonoGame</td>\n",
       "      <td>C#</td>\n",
       "      <td>﻿# MonoGame\\n\\nOne framework for creating powe...</td>\n",
       "      <td>monogam one framework for creat power cross pl...</td>\n",
       "      <td>monogame one framework for creating powerful c...</td>\n",
       "      <td>monogame one framework creating powerful cross...</td>\n",
       "      <td>212</td>\n",
       "      <td>626</td>\n",
       "      <td>[monogame, one, framework, creating, powerful,...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>umutisik/Eigentechno</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>## Eigentechno\\n\\nCode for applying Principal ...</td>\n",
       "      <td>eigentechno code for appli princip compon anal...</td>\n",
       "      <td>eigentechno code for applying principal compon...</td>\n",
       "      <td>eigentechno code applying principal component ...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>[eigentechno, code, applying, principal, compo...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beetbox/beets</td>\n",
       "      <td>Python</td>\n",
       "      <td>.. image:: https://img.shields.io/pypi/v/beets...</td>\n",
       "      <td>imag http img shield io pypi v beet svg target...</td>\n",
       "      <td>image http img shield io pypi v beet svg targe...</td>\n",
       "      <td>image http img shield io pypi v beet svg targe...</td>\n",
       "      <td>205</td>\n",
       "      <td>518</td>\n",
       "      <td>[image, http, img, shield, io, pypibeet, svg, ...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>j2kao/fcc_nn_research</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># fcc_nn_research\\n\\n(somewhat) cleaned-up ver...</td>\n",
       "      <td>fcc nn research somewhat clean up version of n...</td>\n",
       "      <td>fcc nn research somewhat cleaned up version of...</td>\n",
       "      <td>fcc nn research somewhat cleaned version noteb...</td>\n",
       "      <td>154</td>\n",
       "      <td>283</td>\n",
       "      <td>[fcc, nn, research, somewhat, cleaned, version...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             repo          language  \\\n",
       "48                Hextris/hextris        JavaScript   \n",
       "71               ahmia/ahmia-site            Python   \n",
       "54                OptiKey/OptiKey                C#   \n",
       "27           nprapps/app-template        JavaScript   \n",
       "21          atlemo/SubtlePatterns              HTML   \n",
       "..                            ...               ...   \n",
       "63  EFForg/action-center-platform              Ruby   \n",
       "42              MonoGame/MonoGame                C#   \n",
       "79           umutisik/Eigentechno  Jupyter Notebook   \n",
       "2                   beetbox/beets            Python   \n",
       "69          j2kao/fcc_nn_research  Jupyter Notebook   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "48  Hextris\\n==========\\n\\n<img src=\"images/twitte...   \n",
       "71  [![Build Status](https://travis-ci.org/ahmia/a...   \n",
       "54  # OptiKey\\n\\nOptiKey is an on-screen keyboard ...   \n",
       "27  nprviz's Project Template\\n===================...   \n",
       "21  Subtle Patterns\\n===============\\n\\nView all t...   \n",
       "..                                                ...   \n",
       "63  [![Build Status](https://travis-ci.org/EFForg/...   \n",
       "42  ﻿# MonoGame\\n\\nOne framework for creating powe...   \n",
       "79  ## Eigentechno\\n\\nCode for applying Principal ...   \n",
       "2   .. image:: https://img.shields.io/pypi/v/beets...   \n",
       "69  # fcc_nn_research\\n\\n(somewhat) cleaned-up ver...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "48  hextri img src imag twitter opengraph png widt...   \n",
       "71  build statu http travi ci org ahmia ahmia site...   \n",
       "54  optikey optikey is an on screen keyboard that ...   \n",
       "27  nprviz' project templat about thi templat abou...   \n",
       "21  subtl pattern view all the pattern from subtl ...   \n",
       "..                                                ...   \n",
       "63  build statu http travi ci org efforg action ce...   \n",
       "42  monogam one framework for creat power cross pl...   \n",
       "79  eigentechno code for appli princip compon anal...   \n",
       "2   imag http img shield io pypi v beet svg target...   \n",
       "69  fcc nn research somewhat clean up version of n...   \n",
       "\n",
       "                                           lemmatized  \\\n",
       "48  hextris img src image twitter opengraph png wi...   \n",
       "71  build status http travis ci org ahmia ahmia si...   \n",
       "54  optikey optikey is an on screen keyboard that ...   \n",
       "27  nprviz's project template about this template ...   \n",
       "21  subtle pattern view all the pattern from subtl...   \n",
       "..                                                ...   \n",
       "63  build status http travis ci org efforg action ...   \n",
       "42  monogame one framework for creating powerful c...   \n",
       "79  eigentechno code for applying principal compon...   \n",
       "2   image http img shield io pypi v beet svg targe...   \n",
       "69  fcc nn research somewhat cleaned up version of...   \n",
       "\n",
       "                                                clean  stopwords_removed  \\\n",
       "48  hextris img src image twitter opengraph png wi...                 91   \n",
       "71  build status http travis ci org ahmia ahmia si...                206   \n",
       "54  optikey optikey screen keyboard designed help ...                117   \n",
       "27  nprviz template template template assumption a...                222   \n",
       "21  subtle pattern view pattern subtle pattern htt...                 33   \n",
       "..                                                ...                ...   \n",
       "63  build status http travis ci org efforg action ...                449   \n",
       "42  monogame one framework creating powerful cross...                212   \n",
       "79  eigentechno code applying principal component ...                  3   \n",
       "2   image http img shield io pypi v beet svg targe...                205   \n",
       "69  fcc nn research somewhat cleaned version noteb...                154   \n",
       "\n",
       "    doc_length                                              words  \\\n",
       "48         170  [hextris, img, src, image, twitter, opengraph,...   \n",
       "71         690  [build, status, http, travis, ci, org, ahmia, ...   \n",
       "54         235  [optikey, optikey, screen, keyboard, designed,...   \n",
       "27         304  [nprviz, template, template, template, assumpt...   \n",
       "21          73  [subtle, pattern, view, pattern, subtle, patte...   \n",
       "..         ...                                                ...   \n",
       "63         986  [build, status, http, travis, ci, org, efforg,...   \n",
       "42         626  [monogame, one, framework, creating, powerful,...   \n",
       "79          22  [eigentechno, code, applying, principal, compo...   \n",
       "2          518  [image, http, img, shield, io, pypibeet, svg, ...   \n",
       "69         283  [fcc, nn, research, somewhat, cleaned, version...   \n",
       "\n",
       "    unique_word_count  \n",
       "48                105  \n",
       "71                267  \n",
       "54                136  \n",
       "27                173  \n",
       "21                 44  \n",
       "..                ...  \n",
       "63                407  \n",
       "42                249  \n",
       "79                 20  \n",
       "2                 228  \n",
       "69                174  \n",
       "\n",
       "[76 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run a similar set of t-tests to compare the unique word count for each programming language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Python              387.461538\n",
       "Ruby                286.444444\n",
       "C++                 269.833333\n",
       "JavaScript          225.863636\n",
       "C#                  192.500000\n",
       "Scala               185.500000\n",
       "HTML                169.125000\n",
       "TypeScript          125.500000\n",
       "C                   125.000000\n",
       "CSS                 115.000000\n",
       "Jupyter Notebook     89.600000\n",
       "Java                 83.000000\n",
       "Name: unique_word_count, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('language').unique_word_count.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Unique Word Count T-Test: Python & JavaScript\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Python and JavaScript\n",
      "H_a: There is a difference in the mean number of unique words for Python and JavaScript\n",
      "\n",
      "\n",
      "p-value: 0.031652954785133074\n",
      "t-statistic: 1.9217650547719476\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Python is larger than JavaScript\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Python & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Python and Jupyter Notebook\n",
      "H_a: There is a difference in the mean number of unique words for Python and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.038384786732243714\n",
      "t-statistic: 1.89172927906776\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Python is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Ruby & TypeScript\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Ruby and TypeScript\n",
      "H_a: There is a difference in the mean number of unique words for Ruby and TypeScript\n",
      "\n",
      "\n",
      "p-value: 0.011037979329665937\n",
      "t-statistic: 2.7610018115747983\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Ruby is larger than TypeScript\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Ruby & C\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Ruby and C\n",
      "H_a: There is a difference in the mean number of unique words for Ruby and C\n",
      "\n",
      "\n",
      "p-value: 0.016524719350796222\n",
      "t-statistic: 2.514799926572868\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Ruby is larger than C\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Ruby & CSS\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Ruby and CSS\n",
      "H_a: There is a difference in the mean number of unique words for Ruby and CSS\n",
      "\n",
      "\n",
      "p-value: 0.0027237749326322344\n",
      "t-statistic: 3.5299184629860294\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Ruby is larger than CSS\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Ruby & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Ruby and Jupyter Notebook\n",
      "H_a: There is a difference in the mean number of unique words for Ruby and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.0002886329185740847\n",
      "t-statistic: 4.632838429481496\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Ruby is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: Ruby & Java\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for Ruby and Java\n",
      "H_a: There is a difference in the mean number of unique words for Ruby and Java\n",
      "\n",
      "\n",
      "p-value: 0.005488570132643546\n",
      "t-statistic: 3.1916676256981606\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for Ruby is larger than Java\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: C++ & TypeScript\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for C++ and TypeScript\n",
      "H_a: There is a difference in the mean number of unique words for C++ and TypeScript\n",
      "\n",
      "\n",
      "p-value: 0.016058549727799257\n",
      "t-statistic: 2.77716300910005\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for C++ is larger than TypeScript\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: C++ & C\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for C++ and C\n",
      "H_a: There is a difference in the mean number of unique words for C++ and C\n",
      "\n",
      "\n",
      "p-value: 0.029572900171230713\n",
      "t-statistic: 2.323734312201227\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for C++ is larger than C\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: C++ & CSS\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for C++ and CSS\n",
      "H_a: There is a difference in the mean number of unique words for C++ and CSS\n",
      "\n",
      "\n",
      "p-value: 0.004972770961616361\n",
      "t-statistic: 3.503537124966753\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for C++ is larger than CSS\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: C++ & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for C++ and Jupyter Notebook\n",
      "H_a: There is a difference in the mean number of unique words for C++ and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.0010528544494770762\n",
      "t-statistic: 4.261752546774598\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for C++ is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: C++ & Java\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for C++ and Java\n",
      "H_a: There is a difference in the mean number of unique words for C++ and Java\n",
      "\n",
      "\n",
      "p-value: 0.01147401739790692\n",
      "t-statistic: 3.0350625865846124\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for C++ is larger than Java\n",
      "\n",
      " \n",
      "\n",
      "----------------\n",
      "Unique Word Count T-Test: JavaScript & Jupyter Notebook\n",
      "----------------\n",
      "Hypotheses:\n",
      "H_0: There is no difference in the mean number of unique words for JavaScript and Jupyter Notebook\n",
      "H_a: There is a difference in the mean number of unique words for JavaScript and Jupyter Notebook\n",
      "\n",
      "\n",
      "p-value: 0.033225242793625195\n",
      "t-statistic: 1.9191452092338899\n",
      "We reject the null hypothesis\n",
      "\n",
      "\n",
      "The mean number of unique words for JavaScript is larger than Jupyter Notebook\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell block looks at every pair of languages and compares the document lengths using a t-test\n",
    "\n",
    "# Start by developing two identical lists of all of the languages represented in the train dataset\n",
    "# We will use the languages represented in the array above so that the output below is sorted in a similar manner\n",
    "# When this is converted to a function, we can generate the list in a more generalized manner\n",
    "train_language_list_1 = list(train.groupby('language').unique_word_count.mean().sort_values(ascending=False).index)\n",
    "train_language_list_2 = list(train.groupby('language').unique_word_count.mean().sort_values(ascending=False).index)\n",
    "\n",
    "# This empty list will hold information about which pairs have been tested. \n",
    "# If the python and javascript pair has already be tested, then we do not need to test the javascript and python pair\n",
    "testing_pairs = []\n",
    "\n",
    "for language_1 in train_language_list_1: # Iterates through list 1\n",
    "    for language_2 in train_language_list_2: # Iterates through list 2 in entirety for each element in list 1\n",
    "        \n",
    "        if language_1 == language_2: # Cannot run a t-test against itself, so skip the test if the two list elements are identical\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            alpha = 0.05 # Set alpha\n",
    "            \n",
    "            # Run the t-test and store the t-statistic and the p-value\n",
    "            stat, p = stats.ttest_ind(train[train.language == language_1].unique_word_count, train[train.language == language_2].unique_word_count)\n",
    "            \n",
    "            # If the p-value is statistically significant we print the results, otherwise we do nothing\n",
    "            if p/2 < alpha:\n",
    "                \n",
    "                # Creating strings to represent the pair that is being tested (eg. 'Python and JavaScript' & 'JavaScript and Python')\n",
    "                testing_pair_1 = language_1 + \" \" + language_2\n",
    "                testing_pair_2 = language_2 + \" \" + language_1\n",
    "                \n",
    "                # If this unique pair has not yet been tested:\n",
    "                if (testing_pair_1 not in testing_pairs) and (testing_pair_2 not in testing_pairs):\n",
    "                    \n",
    "                    # Add this pair to the testing_pairs list so that we do not output duplicate t-test results\n",
    "                    testing_pairs.append(testing_pair_1)\n",
    "                    testing_pairs.append(testing_pair_2)\n",
    "                    \n",
    "                    # Print the results of the test\n",
    "                    print(\"----------------\")\n",
    "                    print(f\"Unique Word Count T-Test: {language_1} & {language_2}\")\n",
    "                    print(\"----------------\")\n",
    "                    print(\"Hypotheses:\")\n",
    "                    print(f\"H_0: There is no difference in the mean number of unique words for {language_1} and {language_2}\")\n",
    "                    print(f\"H_a: There is a difference in the mean number of unique words for {language_1} and {language_2}\")\n",
    "                    print('\\n')\n",
    "                    print(f\"p-value: {p/2}\")\n",
    "                    print(f\"t-statistic: {stat}\")\n",
    "                    print(f\"We reject the null hypothesis\")\n",
    "                    print(\"\\n\")\n",
    "                    if stat < 0:\n",
    "                        print(f\"The mean number of unique words for {language_1} is smaller than {language_2}\")\n",
    "                    elif stat > 0:\n",
    "                        print(f\"The mean number of unique words for {language_1} is larger than {language_2}\")\n",
    "                    print('\\n','\\n')\n",
    "                    \n",
    "                    # If the pair had already been tested, do not print any results and continue through the loop\n",
    "                else:\n",
    "                    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
